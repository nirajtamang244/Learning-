{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niraj GPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feeding the model with some baby conversation to learn from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dialogs.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(0, len(lines) - 1, 2):\n",
    "    input_text = lines[i].strip().lower()\n",
    "    output_text = lines[i+1].strip().lower()\n",
    "    data.append((input_text, output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "all_text = [text for pair in data for text in pair]\n",
    "words = set(\" \".join(all_text).split())\n",
    "word2idx = {word: i+1 for i, word in enumerate(words)}  # Start from 1\n",
    "word2idx[\"<PAD>\"] = 0  # Add padding token\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(sentence):\n",
    "    return [word2idx[word] for word in sentence.split()]\n",
    "\n",
    "X = [encode(pair[0]) for pair in data]\n",
    "Y = [encode(pair[1]) for pair in data]\n",
    "\n",
    "\n",
    "X = [torch.tensor(x) for x in X]\n",
    "Y = [torch.tensor(y) for y in Y]\n",
    "\n",
    "X_pad = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "Y_pad = pad_sequence(Y, batch_first=True, padding_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MiniNirajGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "vocab_size = len(word2idx)\n",
    "model = MiniNirajGPT(vocab_size=vocab_size, embed_dim=16, hidden_dim=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.0000\n",
      "Epoch 100, Loss: 0.0000\n",
      "Epoch 150, Loss: 0.0000\n",
      "Epoch 200, Loss: 0.0000\n",
      "Epoch 250, Loss: 0.0000\n",
      "Epoch 300, Loss: 0.0000\n",
      "Epoch 350, Loss: 0.0000\n",
      "Epoch 400, Loss: 0.0000\n",
      "Epoch 450, Loss: 0.0000\n",
      "Epoch 500, Loss: 0.0000\n",
      "Epoch 550, Loss: 0.0000\n",
      "Epoch 600, Loss: 0.0000\n",
      "Epoch 650, Loss: 0.0000\n",
      "Epoch 700, Loss: 0.0000\n",
      "Epoch 750, Loss: 0.0000\n",
      "Epoch 800, Loss: 0.0000\n",
      "Epoch 850, Loss: 0.0000\n",
      "Epoch 900, Loss: 0.0000\n",
      "Epoch 950, Loss: 0.0000\n",
      "Epoch 1000, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.000001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in zip(X_pad, Y_pad):\n",
    "        if x.size(0) != y.size(0):  # üõ°Ô∏è Skip mismatched pairs\n",
    "            continue\n",
    "\n",
    "        x = x.unsqueeze(0)  # Shape: [1, seq_len]\n",
    "        y = y.unsqueeze(0)\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        out = out.view(-1, vocab_size)\n",
    "        y = y.view(-1)\n",
    "\n",
    "        loss = loss_fn(out, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 50 == 49:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(input_text):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        words = input_text.lower().split()\n",
    "\n",
    "        # Handle unknown words using <PAD> token\n",
    "        input_ids = [word2idx[word] if word in word2idx else word2idx[\"<PAD>\"] for word in words]\n",
    "\n",
    "        input_tensor = torch.tensor(input_ids).unsqueeze(0)\n",
    "\n",
    "        output = model(input_tensor)\n",
    "\n",
    "        # Grab most likely word at each position\n",
    "        output_ids = output.argmax(dim=2)  # Shape: [1, seq_len]\n",
    "\n",
    "        # ‚ö†Ô∏è .squeeze() can turn it into an int if it's only 1 word, so we use .tolist() carefully:\n",
    "        if output_ids.numel() == 1:\n",
    "            output_ids = [output_ids.item()]  # make it a list with 1 number\n",
    "        else:\n",
    "            output_ids = output_ids.squeeze().tolist()\n",
    "\n",
    "        response_words = [idx2word.get(idx, \"<UNK>\") for idx in output_ids]\n",
    "        response = \" \".join(response_words)\n",
    "\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniGeorgeGPT is ready! Type 'quit' to stop.\n",
      "\n",
      "MiniGeorgeGPT: cleaner. height some. jokes. careful.\n",
      "MiniGeorgeGPT: noise?\n"
     ]
    }
   ],
   "source": [
    "print(\"MiniGeorgeGPT is ready! Type 'quit' to stop.\\n\")\n",
    "while True:\n",
    "    msg = input(\"You: \")\n",
    "    if msg.lower() == \"quit\":\n",
    "        break\n",
    "    reply = chat(msg)\n",
    "    print(\"MiniGeorgeGPT:\", reply)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
